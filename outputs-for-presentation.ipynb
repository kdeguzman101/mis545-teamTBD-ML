{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mHAPoJhsvWFD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report, roc_curve,\n",
    "    roc_auc_score, precision_recall_curve, recall_score, precision_score, f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6zm0XNQ_dxG"
   },
   "source": [
    "# Specify file path and create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "777TvXBzDmkN"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_id = '17eoOjbTriXdOnuUC2LSHDe-9lA-V_h1X'   # File ID from Google Drive points to the dataset\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Send GET request to download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Use io.BytesIO to read the content into pandas directly\n",
    "df = pd.read_csv(io.BytesIO(response.content))\n",
    "\n",
    "# Create target variable column, \"Graduated\" based on Graduation_Rate\n",
    "df['Graduated'] = (df['Graduation_Rate'] >= 0.6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kSSCdwaE_dxH"
   },
   "outputs": [],
   "source": [
    "# Setup columns that need to be scaled or encoded\n",
    "numerical_columns = [\"GPA\", \"SAT_Score\", \"ACT_Score\", \"Family_Size\", \"Support_Center_Utilization\",\n",
    "                     \"Retention_Rate\", \"Graduation_Age\", \"Study_Hours_Per_Week\", \"Student_Loan_Amount\", \"Distance_From_Home\", \"Work_Hours_Per_Week\"]\n",
    "nominal_columns = [\"Marital_Status\", \"Life_Event\", \"Major\"]\n",
    "ordinal_columns = [\"Income_Level\", \"Institution_Type\", \"Campus_Engagement\", \"First_Gen_Student\", \"Enrollment_Status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQ64O9UeA44"
   },
   "source": [
    "Displaying the split between \"Graduated\" 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Pen3Eha1eAbP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graduated\n",
       "1    7159\n",
       "0    2841\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Graduated'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghk4Q3l3YF1c"
   },
   "source": [
    "Display the dataset and information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "1cNJw5_vYEwE",
    "outputId": "871d8958-d880-4cb1-90f2-6bb4e562d01e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>GPA</th>\n",
       "      <th>SAT_Score</th>\n",
       "      <th>ACT_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Support_Center_Utilization</th>\n",
       "      <th>Retention_Rate</th>\n",
       "      <th>Graduation_Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Graduation_Age</th>\n",
       "      <th>Major</th>\n",
       "      <th>Study_Hours_Per_Week</th>\n",
       "      <th>Student_Loan_Amount</th>\n",
       "      <th>Campus_Engagement</th>\n",
       "      <th>First_Gen_Student</th>\n",
       "      <th>Enrollment_Status</th>\n",
       "      <th>Distance_From_Home</th>\n",
       "      <th>Work_Hours_Per_Week</th>\n",
       "      <th>Graduated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1174</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>...</td>\n",
       "      <td>22.3</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13.3</td>\n",
       "      <td>30968.51</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1079</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>25.1</td>\n",
       "      <td>18679.95</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1197</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>22.4</td>\n",
       "      <td>Education</td>\n",
       "      <td>15.1</td>\n",
       "      <td>39004.41</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>62.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1328</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>22.5</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15563.23</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>93.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1064</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>22.9</td>\n",
       "      <td>Arts</td>\n",
       "      <td>21.8</td>\n",
       "      <td>6533.81</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>63.1</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1064</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>22.5</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28718.06</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>64.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1336</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Arts</td>\n",
       "      <td>17.1</td>\n",
       "      <td>21571.52</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>65.2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1215</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Health Sciences</td>\n",
       "      <td>15.3</td>\n",
       "      <td>8249.42</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>95.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1029</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1</td>\n",
       "      <td>Arts</td>\n",
       "      <td>15.7</td>\n",
       "      <td>19196.86</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Part-Time</td>\n",
       "      <td>65.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1181</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>3.1</td>\n",
       "      <td>16445.08</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>90.8</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1030</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Arts</td>\n",
       "      <td>17.2</td>\n",
       "      <td>34594.83</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>80.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2.83</td>\n",
       "      <td>1030</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>23.5</td>\n",
       "      <td>STEM</td>\n",
       "      <td>19.2</td>\n",
       "      <td>27574.51</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1136</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>Health Sciences</td>\n",
       "      <td>19.2</td>\n",
       "      <td>12766.71</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>59.7</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student_ID   GPA  SAT_Score  ACT_Score  Family_Size Income_Level  \\\n",
       "0            1  2.73       1174         26            1         High   \n",
       "1            2  2.61       1079         24            4         High   \n",
       "2            3  2.81       1197         26            4          Low   \n",
       "3            4  3.35       1328         29            1         High   \n",
       "4            5  3.02       1064         23            1       Middle   \n",
       "5            6  2.43       1064         23            1       Middle   \n",
       "6            7  3.64       1336         30            4          Low   \n",
       "7            8  2.80       1215         27            1          Low   \n",
       "8            9  2.32       1029         23            1       Middle   \n",
       "9           10  3.20       1181         26            1       Middle   \n",
       "10          11  2.85       1030         23            4       Middle   \n",
       "11          12  2.83       1030         23            2       Middle   \n",
       "12          13  2.45       1136         25            2          Low   \n",
       "\n",
       "   Marital_Status  Support_Center_Utilization  Retention_Rate  \\\n",
       "0         Married                        0.23            0.72   \n",
       "1         Married                        0.15            0.68   \n",
       "2         Married                        0.47            0.61   \n",
       "3        Divorced                        0.00            0.90   \n",
       "4          Single                        0.22            0.61   \n",
       "5        Divorced                        0.26            0.54   \n",
       "6          Single                        0.28            0.71   \n",
       "7          Single                        0.36            0.86   \n",
       "8          Single                        0.56            0.56   \n",
       "9         Married                        0.37            1.00   \n",
       "10         Single                        0.37            0.79   \n",
       "11         Single                        0.42            0.75   \n",
       "12         Single                        0.57            0.55   \n",
       "\n",
       "    Graduation_Rate  ... Graduation_Age            Major  \\\n",
       "0              0.62  ...           22.3             STEM   \n",
       "1              0.63  ...           23.0             STEM   \n",
       "2              0.58  ...           22.4        Education   \n",
       "3              0.90  ...           22.5             STEM   \n",
       "4              0.66  ...           22.9             Arts   \n",
       "5              0.58  ...           22.5             STEM   \n",
       "6              0.65  ...           22.0             Arts   \n",
       "7              0.84  ...           23.0  Health Sciences   \n",
       "8              0.56  ...           23.1             Arts   \n",
       "9              0.99  ...           22.0         Business   \n",
       "10             0.78  ...           22.0             Arts   \n",
       "11             0.67  ...           23.5             STEM   \n",
       "12             0.50  ...           22.6  Health Sciences   \n",
       "\n",
       "    Study_Hours_Per_Week Student_Loan_Amount  Campus_Engagement  \\\n",
       "0                   13.3            30968.51                Low   \n",
       "1                   25.1            18679.95                Low   \n",
       "2                   15.1            39004.41                Low   \n",
       "3                   13.1            15563.23                Low   \n",
       "4                   21.8             6533.81                Low   \n",
       "5                   13.0            28718.06             Medium   \n",
       "6                   17.1            21571.52                Low   \n",
       "7                   15.3             8249.42               High   \n",
       "8                   15.7            19196.86                Low   \n",
       "9                    3.1            16445.08             Medium   \n",
       "10                  17.2            34594.83                Low   \n",
       "11                  19.2            27574.51                Low   \n",
       "12                  19.2            12766.71                Low   \n",
       "\n",
       "    First_Gen_Student Enrollment_Status  Distance_From_Home  \\\n",
       "0               False         Full-Time                42.0   \n",
       "1                True         Full-Time                 5.0   \n",
       "2               False         Full-Time                62.9   \n",
       "3               False         Full-Time                93.1   \n",
       "4               False         Full-Time                63.1   \n",
       "5               False         Full-Time                64.8   \n",
       "6               False         Full-Time                65.2   \n",
       "7               False         Full-Time                95.8   \n",
       "8               False         Part-Time                65.8   \n",
       "9               False         Full-Time                90.8   \n",
       "10              False         Full-Time                80.1   \n",
       "11              False         Full-Time                 0.0   \n",
       "12               True         Full-Time                59.7   \n",
       "\n",
       "   Work_Hours_Per_Week  Graduated  \n",
       "0                 16.9          1  \n",
       "1                  4.4          1  \n",
       "2                  9.5          0  \n",
       "3                  4.2          1  \n",
       "4                 15.5          1  \n",
       "5                 14.7          0  \n",
       "6                  8.7          1  \n",
       "7                  8.9          1  \n",
       "8                  8.3          0  \n",
       "9                 14.4          1  \n",
       "10                15.4          1  \n",
       "11                 6.1          1  \n",
       "12                22.6          0  \n",
       "\n",
       "[13 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first several rows of the dataframe\n",
    "df.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0qeC05vTo6qY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student_ID                       0\n",
      "GPA                              0\n",
      "SAT_Score                        0\n",
      "ACT_Score                        0\n",
      "Family_Size                      0\n",
      "Income_Level                     0\n",
      "Marital_Status                   0\n",
      "Support_Center_Utilization       0\n",
      "Retention_Rate                   0\n",
      "Graduation_Rate                  0\n",
      "Life_Event                    6022\n",
      "Institution_Type                 0\n",
      "Graduation_Age                   0\n",
      "Major                            0\n",
      "Study_Hours_Per_Week             0\n",
      "Student_Loan_Amount              0\n",
      "Campus_Engagement                0\n",
      "First_Gen_Student                0\n",
      "Enrollment_Status                0\n",
      "Distance_From_Home               0\n",
      "Work_Hours_Per_Week              0\n",
      "Graduated                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing empty values in Life_event to 'None'\n",
    "df['Life_Event'] = df['Life_Event'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rb4kqbOO_dxJ",
    "outputId": "ea7ee2d0-d120-458e-9cf2-dd700a5a0349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 6700\n",
      "Number of testing samples: 3300\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = df.drop(columns=[\"Student_ID\", \"Graduation_Rate\", \"Graduated\"])\n",
    "y = df[\"Graduated\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of testing samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPA', 'SAT_Score', 'ACT_Score', 'Family_Size', 'Income_Level', 'Marital_Status', 'Support_Center_Utilization', 'Retention_Rate', 'Life_Event', 'Institution_Type', 'Graduation_Age', 'Major', 'Study_Hours_Per_Week', 'Student_Loan_Amount', 'Campus_Engagement', 'First_Gen_Student', 'Enrollment_Status', 'Distance_From_Home', 'Work_Hours_Per_Week']\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.columns.tolist()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch for K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),  # Scale numeric columns\n",
    "        ('cat', OneHotEncoder(), nominal_columns),  # One-hot encode categorical columns\n",
    "        ('ord', OrdinalEncoder(), ordinal_columns)  # Ordinal encode ordinal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "param_grid = {\n",
    "    'model__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on training data\n",
    "train_predictions = best_knn_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "# Make predictions on testing data\n",
    "test_predictions = best_knn_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "report = classification_report(y_test, test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\\n\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\\n\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\\n\")\n",
    "print(f\"Training F1: {train_f1:.4f}\")\n",
    "print(f\"Test F1: {test_f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix, \"\\n\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__C': 0.1, 'model__penalty': 'l2', 'model__solver': 'saga'}\n",
      "Training Accuracy: 0.9104\n",
      "Testing Accuracy: 0.9064\n",
      "\n",
      "Training Recall: 0.9441\n",
      "Test Recall: 0.9399\n",
      "\n",
      "Training Precision: 0.9321\n",
      "Test Precision: 0.9292\n",
      "\n",
      "Training F1: 0.9381\n",
      "Test F1: 0.9345\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 785  168]\n",
      " [ 141 2206]] \n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84       953\n",
      "           1       0.93      0.94      0.93      2347\n",
      "\n",
      "    accuracy                           0.91      3300\n",
      "   macro avg       0.89      0.88      0.89      3300\n",
      "weighted avg       0.91      0.91      0.91      3300\n",
      " \n",
      "\n",
      "Predicted Class Distribution: [ 926 2374]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),  # Scale numeric columns\n",
    "        ('cat', OneHotEncoder(), nominal_columns),  # One-hot encode categorical columns\n",
    "        ('ord', OrdinalEncoder(), ordinal_columns)  # Ordinal encode ordinal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1.0, 10.0],\n",
    "    'model__solver': ['liblinear', 'saga'],\n",
    "    'model__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_logistic_regression_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on training data\n",
    "train_predictions = best_logistic_regression_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "# Make predictions on testing data\n",
    "test_predictions = best_logistic_regression_model.predict(X_test)\n",
    "y_test_proba = best_logistic_regression_model.predict_proba(X_test)[:, 1]\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "report = classification_report(y_test, test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\\n\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\\n\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\\n\")\n",
    "print(f\"Training F1: {train_f1:.4f}\")\n",
    "print(f\"Test F1: {test_f1:.4f}\\n\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix, \"\\n\")\n",
    "print(\"Classification Report:\\n\", report, \"\\n\")\n",
    "print(f\"Predicted Class Distribution: {np.bincount(test_predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJqIsQTcJ5bA"
   },
   "outputs": [],
   "source": [
    "# Visualization 1: Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Not Graduated\", \"Graduated\"], yticklabels=[\"Not Graduated\", \"Graduated\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\", color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Precision-Recall Curve (with zero_division parameter)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_test_proba)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall, precision, label=\"Precision-Recall Curve\", color='green')\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code that iterates through different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the preprocessor (without scaling for models that don't need it)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), nominal_columns),      # One-hot encode categorical columns\n",
    "        ('ord', OrdinalEncoder(), ordinal_columns)    # Ordinal encode ordinal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "# List of models to iterate over\n",
    "models = [\n",
    "    ('Support Vector Machine', SVC()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Naive Bayes', GaussianNB())\n",
    "]\n",
    "\n",
    "# Iterate through models and compare train and test accuracy\n",
    "for model_name, model in models:\n",
    "    # If the model requires scaling, add StandardScaler\n",
    "    if isinstance(model, SVC):  # these models requires scaling\n",
    "        preprocessor_with_scaling = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numerical_columns),  # Scale numeric columns\n",
    "                ('cat', OneHotEncoder(), nominal_columns),      # One-hot encode categorical columns\n",
    "                ('ord', OrdinalEncoder(), ordinal_columns)    # Ordinal encode ordinal columns\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor_with_scaling = preprocessor  # Use the preprocessor without scaling for other models\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor_with_scaling),  # Preprocessing steps\n",
    "        ('model', model)  # Model\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training and test data\n",
    "    train_predictions = pipeline.predict(X_train)\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy on the training set\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    train_recall = recall_score(y_train, train_predictions)\n",
    "    train_precision = precision_score(y_train, train_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    test_recall = recall_score(y_test, test_predictions)\n",
    "    test_precision = precision_score(y_test, test_predictions)\n",
    "    test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "    # Print the model and its accuracy results\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.4f}\\n\")\n",
    "    print(f\"  Training Recall: {train_recall:.4f}\")\n",
    "    print(f\"  Test Recall: {test_recall:.4f}\\n\")\n",
    "    print(f\"  Training Precision: {train_precision:.4f}\")\n",
    "    print(f\"  Test Precision: {test_precision:.4f}\\n\")\n",
    "    print(f\"  Training F1: {train_f1:.4f}\")\n",
    "    print(f\"  Test F1: {test_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 6700\n",
      "Number of testing samples: 3300\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m                 output_feature_names\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns])\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_feature_names\n\u001b[0;32m---> 75\u001b[0m transformed_feature_names \u001b[38;5;241m=\u001b[39m \u001b[43mget_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Create a SHAP explainer\u001b[39;00m\n\u001b[1;32m     78\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mExplainer(pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m], pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(X_train))\n",
      "Cell \u001b[0;32mIn[16], line 67\u001b[0m, in \u001b[0;36mget_feature_names\u001b[0;34m(column_transformer)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_feature_names_out\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 67\u001b[0m     output_feature_names\u001b[38;5;241m.\u001b[39mextend(\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(columns, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/python-coding/mis545-teamTBD-ML/.venv/lib/python3.11/site-packages/sklearn/base.py:1143\u001b[0m, in \u001b[0;36mOneToOneFeatureMixin.get_feature_names_out\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \n\u001b[1;32m   1126\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;124;03m        Same as input features.\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_features_in_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check_feature_names_in(\u001b[38;5;28mself\u001b[39m, input_features)\n",
      "File \u001b[0;32m~/python-coding/mis545-teamTBD-ML/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "file_id = '17eoOjbTriXdOnuUC2LSHDe-9lA-V_h1X'   # File ID from Google Drive points to the dataset\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Send GET request to download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Use io.BytesIO to read the content into pandas directly\n",
    "df = pd.read_csv(io.BytesIO(response.content))\n",
    "\n",
    "# Create target variable column, \"Graduated\" based on Graduation_Rate\n",
    "df['Graduated'] = (df['Graduation_Rate'] >= 0.6).astype(int)\n",
    "\n",
    "# Prepare data\n",
    "X = df.drop(columns=[\"Student_ID\", \"Graduation_Rate\", \"Graduated\"])\n",
    "y = df[\"Graduated\"]\n",
    "\n",
    "# Extract feature names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Setup columns that need to be scaled or encoded\n",
    "numerical_columns = [\"GPA\", \"SAT_Score\", \"ACT_Score\", \"Family_Size\", \"Support_Center_Utilization\",\n",
    "                     \"Retention_Rate\", \"Graduation_Age\", \"Study_Hours_Per_Week\", \"Student_Loan_Amount\", \"Distance_From_Home\", \"Work_Hours_Per_Week\"]\n",
    "nominal_columns = [\"Marital_Status\", \"Life_Event\", \"Major\"]\n",
    "ordinal_columns = [\"Income_Level\", \"Institution_Type\", \"Campus_Engagement\", \"First_Gen_Student\", \"Enrollment_Status\"]\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),  # Scale numeric columns\n",
    "        ('cat', OneHotEncoder(), nominal_columns),  # One-hot encode categorical columns\n",
    "        ('ord', OrdinalEncoder(), ordinal_columns)  # Ordinal encode ordinal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=1000, C=0.1, penalty='l2', solver='saga'))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get the transformed feature names\n",
    "def get_feature_names(column_transformer):\n",
    "    output_feature_names = []\n",
    "    for name, transformer, columns in column_transformer.transformers:\n",
    "        if name == 'remainder':\n",
    "            continue\n",
    "        if hasattr(transformer, 'get_feature_names_out'):\n",
    "            output_feature_names.extend(transformer.get_feature_names_out())\n",
    "        else:\n",
    "            if isinstance(columns, list):\n",
    "                output_feature_names.extend(columns)\n",
    "            else:\n",
    "                output_feature_names.extend([f\"{name}__{col}\" for col in columns])\n",
    "    return output_feature_names\n",
    "\n",
    "transformed_feature_names = get_feature_names(preprocessor)\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.Explainer(pipeline.named_steps['model'], pipeline.named_steps['preprocessor'].transform(X_train))\n",
    "\n",
    "# Get SHAP values for the test set\n",
    "shap_values = explainer(pipeline.named_steps['preprocessor'].transform(X_test))\n",
    "\n",
    "# Plot feature importance\n",
    "shap.summary_plot(shap_values, pipeline.named_steps['preprocessor'].transform(X_test), feature_names=transformed_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), nominal_columns),  # One-hot encode categorical columns\n",
    "        ('ord', OrdinalEncoder(), ordinal_columns)  # Ordinal encode ordinal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'model__max_depth': [None, 10, 20, 30],  # Depth of the trees\n",
    "    'model__min_samples_split': [2, 5, 10],  # Minimum samples to split\n",
    "    'model__min_samples_leaf': [1, 2, 4],    # Minimum samples at leaf nodes\n",
    "    'model__max_features': ['sqrt', 'log2'],  # Features to consider for each split\n",
    "    'model__bootstrap': [True, False]        # Whether bootstrap sampling is used\n",
    "}\n",
    "\n",
    "# Grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on training data\n",
    "train_predictions = best_rf_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "# Make predictions on testing data\n",
    "test_predictions = best_rf_model.predict(X_test)\n",
    "# y_test_proba = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "report = classification_report(y_test, test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\\n\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\\n\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\\n\")\n",
    "print(f\"Training F1: {train_f1:.4f}\")\n",
    "print(f\"Test F1: {test_f1:.4f}\\n\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix, \"\\n\")\n",
    "print(\"Classification Report:\\n\", report, \"\\n\")\n",
    "print(f\"Predicted Class Distribution: {np.bincount(test_predictions)}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
