{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "mHAPoJhsvWFD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report, roc_curve,\n",
    "    roc_auc_score, precision_recall_curve, recall_score, precision_score, f1_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6zm0XNQ_dxG"
   },
   "source": [
    "Specify file path and create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "777TvXBzDmkN"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_id = '17eoOjbTriXdOnuUC2LSHDe-9lA-V_h1X'   # File ID from Google Drive points to the dataset\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Send GET request to download the file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Use io.BytesIO to read the content into pandas directly\n",
    "df = pd.read_csv(io.BytesIO(response.content))\n",
    "\n",
    "# Create target variable column, \"Graduated\" based on Graduation_Rate\n",
    "df['Graduated'] = (df['Graduation_Rate'] >= 0.6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "kSSCdwaE_dxH"
   },
   "outputs": [],
   "source": [
    "# Setup columns that need to be scaled or encoded\n",
    "numerical_columns = [\"GPA\", \"SAT_Score\", \"ACT_Score\", \"Family_Size\", \"Support_Center_Utilization\",\n",
    "                     \"Retention_Rate\", \"Graduation_Age\", \"Study_Hours_Per_Week\", \"Student_Loan_Amount\", \"Distance_From_Home\", \"Work_Hours_Per_Week\"]\n",
    "nominal_columns = [\"Marital_Status\", \"Life_Event\", \"Major\"]\n",
    "ordinal_columns = [\"Income_Level\", \"Institution_Type\", \"Campus_Engagement\", \"First_Gen_Student\", \"Enrollment_Status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghk4Q3l3YF1c"
   },
   "source": [
    "# Display the dataset and information about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "1cNJw5_vYEwE",
    "outputId": "871d8958-d880-4cb1-90f2-6bb4e562d01e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>GPA</th>\n",
       "      <th>SAT_Score</th>\n",
       "      <th>ACT_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Income_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Support_Center_Utilization</th>\n",
       "      <th>Retention_Rate</th>\n",
       "      <th>Graduation_Rate</th>\n",
       "      <th>Life_Event</th>\n",
       "      <th>Institution_Type</th>\n",
       "      <th>Graduation_Age</th>\n",
       "      <th>Major</th>\n",
       "      <th>Study_Hours_Per_Week</th>\n",
       "      <th>Student_Loan_Amount</th>\n",
       "      <th>Campus_Engagement</th>\n",
       "      <th>First_Gen_Student</th>\n",
       "      <th>Enrollment_Status</th>\n",
       "      <th>Distance_From_Home</th>\n",
       "      <th>Work_Hours_Per_Week</th>\n",
       "      <th>Graduated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1174</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Family Issues</td>\n",
       "      <td>Private</td>\n",
       "      <td>22.3</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13.3</td>\n",
       "      <td>30968.51</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1079</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>23.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>25.1</td>\n",
       "      <td>18679.95</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1197</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>22.4</td>\n",
       "      <td>Education</td>\n",
       "      <td>15.1</td>\n",
       "      <td>39004.41</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>62.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1328</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Health Issues</td>\n",
       "      <td>Public</td>\n",
       "      <td>22.5</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13.1</td>\n",
       "      <td>15563.23</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>93.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1064</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>22.9</td>\n",
       "      <td>Arts</td>\n",
       "      <td>21.8</td>\n",
       "      <td>6533.81</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>63.1</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.43</td>\n",
       "      <td>1064</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>22.5</td>\n",
       "      <td>STEM</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28718.06</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>64.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1336</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Family Issues</td>\n",
       "      <td>Private</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Arts</td>\n",
       "      <td>17.1</td>\n",
       "      <td>21571.52</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>65.2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1215</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>Health Issues</td>\n",
       "      <td>Public</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Health Sciences</td>\n",
       "      <td>15.3</td>\n",
       "      <td>8249.42</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>95.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1029</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>23.1</td>\n",
       "      <td>Arts</td>\n",
       "      <td>15.7</td>\n",
       "      <td>19196.86</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Part-Time</td>\n",
       "      <td>65.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1181</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Family Issues</td>\n",
       "      <td>Public</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Business</td>\n",
       "      <td>3.1</td>\n",
       "      <td>16445.08</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>90.8</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1030</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Arts</td>\n",
       "      <td>17.2</td>\n",
       "      <td>34594.83</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>80.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2.83</td>\n",
       "      <td>1030</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Middle</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.67</td>\n",
       "      <td>Health Issues</td>\n",
       "      <td>Public</td>\n",
       "      <td>23.5</td>\n",
       "      <td>STEM</td>\n",
       "      <td>19.2</td>\n",
       "      <td>27574.51</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1136</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>22.6</td>\n",
       "      <td>Health Sciences</td>\n",
       "      <td>19.2</td>\n",
       "      <td>12766.71</td>\n",
       "      <td>Low</td>\n",
       "      <td>True</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>59.7</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student_ID   GPA  ...  Work_Hours_Per_Week  Graduated\n",
       "0            1  2.73  ...                 16.9          1\n",
       "1            2  2.61  ...                  4.4          1\n",
       "2            3  2.81  ...                  9.5          0\n",
       "3            4  3.35  ...                  4.2          1\n",
       "4            5  3.02  ...                 15.5          1\n",
       "5            6  2.43  ...                 14.7          0\n",
       "6            7  3.64  ...                  8.7          1\n",
       "7            8  2.80  ...                  8.9          1\n",
       "8            9  2.32  ...                  8.3          0\n",
       "9           10  3.20  ...                 14.4          1\n",
       "10          11  2.85  ...                 15.4          1\n",
       "11          12  2.83  ...                  6.1          1\n",
       "12          13  2.45  ...                 22.6          0\n",
       "\n",
       "[13 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first several rows of the dataframe\n",
    "df.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "0qeC05vTo6qY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Student_ID                       0\n",
       "GPA                              0\n",
       "SAT_Score                        0\n",
       "ACT_Score                        0\n",
       "Family_Size                      0\n",
       "Income_Level                     0\n",
       "Marital_Status                   0\n",
       "Support_Center_Utilization       0\n",
       "Retention_Rate                   0\n",
       "Graduation_Rate                  0\n",
       "Life_Event                    6022\n",
       "Institution_Type                 0\n",
       "Graduation_Age                   0\n",
       "Major                            0\n",
       "Study_Hours_Per_Week             0\n",
       "Student_Loan_Amount              0\n",
       "Campus_Engagement                0\n",
       "First_Gen_Student                0\n",
       "Enrollment_Status                0\n",
       "Distance_From_Home               0\n",
       "Work_Hours_Per_Week              0\n",
       "Graduated                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing empty values in Life_event to 'None'\n",
    "df['Life_Event'] = df['Life_Event'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rb4kqbOO_dxJ",
    "outputId": "ea7ee2d0-d120-458e-9cf2-dd700a5a0349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 6700\n",
      "Number of testing samples: 3300\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = df.drop(columns=[\"Student_ID\", \"Graduation_Rate\", \"Graduated\"])\n",
    "y = df[\"Graduated\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of testing samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch for K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__metric': 'euclidean', 'model__n_neighbors': 11, 'model__weights': 'uniform'}\n",
      "Training Accuracy: 0.8851\n",
      "Testing Accuracy: 0.8518\n",
      "\n",
      "Training Recall: 0.9437\n",
      "Test Recall: 0.9225\n",
      "\n",
      "Training Precision: 0.9010\n",
      "Test Precision: 0.8758\n",
      "\n",
      "Training F1: 0.9218\n",
      "Test F1: 0.8985\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),  # Scale numeric columns\n",
    "        ('cat', OneHotEncoder(), nominal_columns),  # One-hot encode categorical columns\n",
    "        ('ord', OrdinalEncoder(), ordinal_columns)  # Ordinal encode ordinal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "param_grid = {\n",
    "    'model__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'model__weights': ['uniform', 'distance'],\n",
    "    'model__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on training data\n",
    "train_predictions = best_knn_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "# Make predictions on testing data\n",
    "test_predictions = best_knn_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "report = classification_report(y_test, test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\\n\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\\n\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\\n\")\n",
    "print(f\"Training F1: {train_f1:.4f}\")\n",
    "print(f\"Test F1: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__C': 0.1, 'model__max_iter': 1000, 'model__penalty': 'l2', 'model__solver': 'saga'}\n",
      "Training Accuracy: 0.9104\n",
      "Testing Accuracy: 0.9064\n",
      "\n",
      "Training Recall: 0.9441\n",
      "Test Recall: 0.9399\n",
      "\n",
      "Training Precision: 0.9321\n",
      "Test Precision: 0.9292\n",
      "\n",
      "Training F1: 0.9381\n",
      "Test F1: 0.9345\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),  # Scale numeric columns\n",
    "        ('cat', OneHotEncoder(), nominal_columns),  # One-hot encode categorical columns\n",
    "        ('ord', OrdinalEncoder(), ordinal_columns)  # Ordinal encode ordinal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1.0, 10.0],\n",
    "    'model__solver': ['liblinear', 'saga'],\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__max_iter': [1000]\n",
    "}\n",
    "\n",
    "# Grid search with pipeline\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_logistic_regression_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on training data\n",
    "train_predictions = best_logistic_regression_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "# Make predictions on testing data\n",
    "test_predictions = best_logistic_regression_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "report = classification_report(y_test, test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\\n\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\\n\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\\n\")\n",
    "print(f\"Training F1: {train_f1:.4f}\")\n",
    "print(f\"Test F1: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code that iterates through different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the preprocessor (without scaling for models that don't need it)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), nominal_columns),      # One-hot encode categorical columns\n",
    "        ('ord', OrdinalEncoder(), ordinal_columns)    # Ordinal encode ordinal columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "# List of models to iterate over\n",
    "models = [\n",
    "    ('Support Vector Machine', SVC()),\n",
    "    ('Random Forest', RandomForestClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Naive Bayes', GaussianNB())\n",
    "]\n",
    "\n",
    "# Iterate through models and compare train and test accuracy\n",
    "for model_name, model in models:\n",
    "    # If the model requires scaling, add StandardScaler\n",
    "    if isinstance(model, SVC):  # these models requires scaling\n",
    "        preprocessor_with_scaling = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numerical_columns),  # Scale numeric columns\n",
    "                ('cat', OneHotEncoder(), nominal_columns),      # One-hot encode categorical columns\n",
    "                ('ord', OrdinalEncoder(), ordinal_columns)    # Ordinal encode ordinal columns\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor_with_scaling = preprocessor  # Use the preprocessor without scaling for other models\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor_with_scaling),  # Preprocessing steps\n",
    "        ('model', model)  # Model\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training and test data\n",
    "    train_predictions = pipeline.predict(X_train)\n",
    "    test_predictions = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy on the training set\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "    # Calculate accuracy on the test set\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "    # Print the model and its accuracy results\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcqSANkRnLWF"
   },
   "source": [
    "# DECISION FOREST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a1_1sYnMHyw",
    "outputId": "067d6ca7-1018-45c3-e144-1ed969637501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9083582089552239\n",
      "Test Accuracy: 0.9051515151515152\n",
      "Confusion Matrix:\n",
      " [[ 818  135]\n",
      " [ 178 2169]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       953\n",
      "           1       0.94      0.92      0.93      2347\n",
      "\n",
      "    accuracy                           0.91      3300\n",
      "   macro avg       0.88      0.89      0.89      3300\n",
      "weighted avg       0.91      0.91      0.91      3300\n",
      "\n",
      "Predicted Class Distribution: [ 996 2304]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(f\"Predicted Class Distribution: {np.bincount(y_test_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgCjRTiCMLcy"
   },
   "outputs": [],
   "source": [
    "# Visualization 1: Confusion Matrix Heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Not Graduated\", \"Graduated\"], yticklabels=[\"Not Graduated\", \"Graduated\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\", color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Precision-Recall Curve (with zero_division parameter)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_test_proba)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(recall, precision, label=\"Precision-Recall Curve\", color='green')\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
